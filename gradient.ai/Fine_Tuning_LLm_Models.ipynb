{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e6CTeeHcdoZ",
        "outputId": "ec5b702e-7060-431f-90b3-c0af14aceaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.11.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.5/375.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.10.5 (from gradientai)\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, pydantic, gradientai\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.1\n",
            "    Uninstalling pydantic-2.7.1:\n",
            "      Successfully uninstalled pydantic-2.7.1\n",
            "Successfully installed aenum-3.1.15 gradientai-1.11.0 pydantic-1.10.15\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_WORKSPACE_ID']='162271bb-9459-4a12-9bc6-bc00fef345d1_workspace'\n",
        "os.environ['GRADIENT_ACCESS_TOKEN']='JvWsKHMbikkGc8oN20lrnVkcxAIIvqm0'\n",
        "!pip install load_dotenv"
      ],
      "metadata": {
        "id": "SU3cUwwacjww",
        "outputId": "d4dcfb43-821d-4421-8e3a-b88f56bb8b81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting load_dotenv\n",
            "  Downloading load_dotenv-0.1.0-py3-none-any.whl (7.2 kB)\n",
            "Collecting python-dotenv (from load_dotenv)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, load_dotenv\n",
            "Successfully installed load_dotenv-0.1.0 python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"Kenil-model\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "\n",
        "    sample_query = \"### Instruction: Which are he things are there that kenil kavar loves the most ? \\n\\n ### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "    ## Before Finetuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(before fine tuning): {completion}\")\n",
        "\n",
        "    samples=[\n",
        "        {\"inputs\":\"### Instruction: Who is Kenil Kavar? \\n\\n### Response: Kenil is a popular student and LinkedIn influencer who uploads post on Data Science,AI And LLM in his ID Kenil Kavar\"},\n",
        "        {\"inputs\":\"### Instruction: Who is this person named Kenil Kavar? \\n\\n### Response: Kenil Kavark Like Data Science And AI And makes post on LinkedIn and he is also a student\"},\n",
        "        {\"inputs\":\"### Instruction: What do you know about Kenil Kavar? \\n\\n### Response: Kenil Kavar is a popular creator who specializes in the field of Data Science and his ID name Kenil Kavar\"},\n",
        "        {\"inputs\":\"### Instruction: Can you tell me about Kenil Kavar? \\n\\n### Response: Kenil Kavar is a student, post creator,and a creator who loves Data Science And AI and LLM's\"}\n",
        "    ]\n",
        "\n",
        "    ## Lets define parameters for finetuning\n",
        "    num_epochs=3\n",
        "    count=0\n",
        "    while count<num_epochs:\n",
        "      print(f\"Fine tuning the model with iteration {count + 1}\")\n",
        "      new_model_adapter.fine_tune(samples=samples)\n",
        "      count=count+1\n",
        "\n",
        "    #after fine tuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(after fine tuning): {completion}\")\n",
        "    new_model_adapter.delete()\n",
        "    gradient.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U5D6rx6deHY",
        "outputId": "a165c011-926b-4e10-d2bb-b4df1161c8b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 3d53c5fa-481f-4a3a-b01d-050fad3ccc47_model_adapter\n",
            "Asking: ### Instruction: Which are he things are there that kenil kavar loves the most ? \n",
            "\n",
            " ### Response:\n",
            "Generated(before fine tuning):  I'm sorry, but I'm not familiar with the name \"kenil kavar\" or any associated preferences. Could you please provide more context or clarify your question?\n",
            "Fine tuning the model with iteration 1\n",
            "Fine tuning the model with iteration 2\n",
            "Fine tuning the model with iteration 3\n",
            "Generated(after fine tuning):  Kenil Kavar loves Data Science and AI and he is passionate about creating content related to these fields.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uifyewQ9dmjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}